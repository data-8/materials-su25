{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4008dd5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw12.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67e2e90",
   "metadata": {},
   "source": [
    "<img src=\"data8logo.png\" alt=\"Data 8 Logo\" style=\"width: 15%; float: right; padding: 1%; margin-right: 2%;\"/>\n",
    "\n",
    "# Homework 12: MLR\n",
    "\n",
    "**Helpful Resource:**\n",
    "\n",
    "- [Python Reference](http://data8.org/su25/reference/): Cheat sheet of helpful array & table methods used in Data 8!\n",
    "\n",
    "**Recommended Reading**: \n",
    "\n",
    "* [Classification](https://www.inferentialthinking.com/chapters/17/Classification.html)\n",
    "* [Multiple Regression](https://inferentialthinking.com/chapters/17/6/Multiple_Regression.html)\n",
    "\n",
    "**Credits**:\n",
    "\n",
    "* **Conan Smallwood** + Fall 2024 Pedagogy Team\n",
    "* **Dagny Streit** + Spring 2025 Pedagogy Team\n",
    "* **Ella DeGuzman & Brandon Su** + Spring 2025 Content Team"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7815e5",
   "metadata": {},
   "source": [
    "Please complete this notebook by filling in the cells provided. **Before you begin, execute the cell below to setup the notebook by importing some helpful libraries.** Each time you start your server, you will need to execute this cell again.\n",
    "\n",
    "For all problems that you must write explanations and sentences for, you **must** provide your answer in the designated space. Moreover, throughout this homework and all future ones, **please be sure to not re-assign variables throughout the notebook!** For example, if you use `max_temperature` in your answer to one question, do not reassign it later on. Otherwise, you will fail tests that you thought you were passing previously!\n",
    "\n",
    "**Deadline:**\n",
    "\n",
    "This assignment is **due Tuesday, 8/12 at 8:00pm PT**. Submissions after this time will be accepted for 24 hours and will incur a 30% penalty. Any submissions later than this 24 hour period will not be accepted unless an extension has been granted as per the [policies](http://data8.org/su25/policies/) page. Turn it in by Monday, 8/11 at 8:00pm PT for 5 extra credit points.\n",
    "\n",
    "<span style=\"color:red\">**Note: This homework has hidden tests on it. That means even though tests may say 100% passed, it doesn't mean your final grade will be 100%. We will be running more tests for correctness once everyone turns in the homework.**</span>\n",
    "\n",
    "Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged. Refer to the [policies](http://data8.org/su25/policies/#learning-cooperatively) page to learn more about how to learn cooperatively.\n",
    "\n",
    "You should start early so that you have time to get help if you're stuck. Office hours are held Monday through Friday in [Warren Hall](https://www.berkeley.edu/map?warren) 101B. The office hours schedule appears [here](http://data8.org/su25/schedule/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f159f1c1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The point breakdown for this assignment is given in the table below:\n",
    "| Category | Points |\n",
    "| --- | --- |\n",
    "| Autograder (Coding questions) | 87 |\n",
    "| Written | 13 |\n",
    "| **Total** | 100 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22e94dd-fb13-4095-b769-21b97fcb538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to set up the notebook, but please don't change it.\n",
    "\n",
    "import numpy as np\n",
    "from datascience import * \n",
    "import hashlib\n",
    "\n",
    "# These lines do some fancy plotting magic.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b62371-ee02-4e89-8d9c-3db1f8477092",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## 1. Exploration of CO2 Emissions Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1ee4d1-3fa6-40f7-9eb5-fada73ca0396",
   "metadata": {},
   "source": [
    "In the following exploration, we will be working with a dataset containing 7385 cars, their specifications, and their CO2 emissions (g/km). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa49fd13",
   "metadata": {},
   "source": [
    "Run the following cell to load information about `co2_raw` and preview the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb1f915-3fa7-4bdd-9a4f-cd2c5a3413d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "co2_raw = Table().read_table(\"CO2 Emissions.csv\").drop(2,5,6,9,10)\n",
    "co2_raw.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cc8891-5e71-4ee5-b684-eb0b80a13983",
   "metadata": {},
   "source": [
    "For the sake of our exploration, let's rename some of the columns and call this new table `co2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef2ddf6-6cbb-4119-a04d-84e786d82ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "co2 = co2_raw.relabeled(\n",
    "    \"Engine Size(L)\", \"Engine\").relabeled(\n",
    "    \"Fuel Consumption City (L/100 km)\", \"Fuel (City)\").relabeled(\n",
    "    \"Fuel Consumption Hwy (L/100 km)\", \"Fuel (Hwy)\").relabeled(\n",
    "    \"CO2 Emissions(g/km)\", \"Emissions\")\n",
    "co2.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db85436-c389-45d5-8cf3-22a5478ec0a2",
   "metadata": {},
   "source": [
    "We aim to predict the average CO2 emissions in grams per kilometer of an unseen car based on its __Engine__, __Cylinders__, __Fuel (City)__, and __Fuel (Hwy)__. To do this, we must first standardize and explore the data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50199e52-7eab-4fe3-abdc-4da0790c0f6b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "__Question 1.1__ Define a function `standardize` that takes in a column name `col` in a table `tbl`, and returns that column as an array in standard units. __(3 Points)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd94e1ed-1c29-49da-89a2-32f83d6feedc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def standardize(tbl, col):\n",
    "    arr = ...\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bb996d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2589d0-8146-4e30-b5e7-80da50f4e0ec",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "__Question 1.2__ Define a function `correlation` that takes in the names of two columns (`x` and `y`) in a table `tbl`, and returns the correlation coefficient `r` between the two columns. __(3 Points)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1130c7d0-cba6-4ed0-a773-6f88766315f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def correlation(tbl, x, y):\n",
    "    ...\n",
    "\n",
    "correlation(co2, \"Engine\", \"Emissions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ff040a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e276bb-9748-4652-b390-897e3cd6fb76",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "__Question 1.3__ Using the function you previously defined, calculate the correlation coefficient between `Emissions` and all other _numerical_ columns in the `co2` table. __(3 Points)__\n",
    "\n",
    "Note: For the sake of passing the public tests, make sure `numerical_column_names` is an array of **strings**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814b3575-5192-42a5-89a2-12474eece37e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numerical_column_names = ...\n",
    "\n",
    "for col_name ...:\n",
    "    current_r = ...\n",
    "    print(f\"{col_name}: {current_r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e248eb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca2f674-22b1-4a08-bc3b-ec4d50d2ff00",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "__Question 1.4__ Which numerical column is most strongly correlated with __Emissions__? Assign `highest_correlation` to the integer corresponding to the correct column. __(3 Points)__\n",
    "\n",
    "1. Engine\n",
    "2. Cylinders\n",
    "3. Fuel (City)\n",
    "4. Fuel (Hwy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f269ddc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "highest_correlation = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3d3061",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6647f99-b3d7-4e8a-9f5f-72ae45c17249",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "---\n",
    "\n",
    "__Question 1.5__ Now, let's visualize the relationship between __Fuel (City)__ and __Emissions__. In the cell below, produce a scatter plot that plots the __Fuel (City)__ and __Emissions__ of every entry in the `co2` table with __Emissions__ on the y-axis. __(3 Points)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84c922f-5e0e-4db9-bed9-dd587d7ecb21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ae56c7-86c6-4284-9abe-f5d9ea35dd09",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "Woah! It looks like the points are very tightly clustered around one line... or, two lines? What could be the cause of this? Let's take another look at our table and see which column could possibly explain what we see in the scatter plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43487ce9-6e6e-449c-a846-68b3b4cc9d50",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "__Question 1.6__ Assign `unique_cylinders_values` to a two-column table: the first column should contain unique value in `Cylinders`; the second column should contain the number of times that each of these unique values appear in the `co2` table. __(3 Points)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3072ad-4008-4682-ad47-ab97113509f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_cylinders_values = ...\n",
    "unique_cylinders_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afb2056",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521f5546-b448-42db-a1ad-4699edac3b74",
   "metadata": {},
   "source": [
    "It seems that most of the cars in the table fall under one of few __Cylinders__ values. Could this explain the split we see in the scatter plot? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd722e47-3df2-43cf-89ea-1fbd552b891b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "__Question 1.7__ Create a table called `co2_new` by adding a new column `Cylinders_and_City` to the `co2` table that is the sum of the columns `Fuel (City)` and `Cylinders`. Then, find the correlation between this new column and `Emissions`. __(3 Points)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c66721-22ce-4cab-bd69-8e74c23f88b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "co2_new = ...\n",
    "strong_correlation = ...\n",
    "strong_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a4005c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f941de-0f8e-4544-860f-f43610b998dd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "__Question 1.8__ True or False: The correlation coefficient between __Emissions__ and the sum of the __Cylinders__ and __Fuel (City)__ columns is _greater_ than the correlation coefficient between __Emissions__ and just the __Fuel (City)__ column. Assign `answer` to either `True` or `False`. __(3 Points)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0ce8a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answer = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020063f2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96596e31-790f-4568-8646-315bccb63aaf",
   "metadata": {},
   "source": [
    "Now, let's visualize this new column on a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f456cf93-1895-4239-97b4-81eb6807379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "co2_new.scatter(\"Cylinders_and_City\", \"Emissions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cd07c6-1ee7-4ace-8a73-cfbb51e173ae",
   "metadata": {},
   "source": [
    "This looks more like a scatter plot that we're used to seeing! A lot of the time, there is more than one variable that contributes to the variable we are trying to predict. Sure, we can just use fuel consumption in the city to predict a car's emission levels, but there are other variables that we aren't accounting for! Including _multiple_ variables in our regression increases our model's ability to capture more complex patterns, and account for multiple factors that may be affecting the variable we want to predict!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e431922-4b9a-4678-bc6b-abcf83d7e9f7",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## 2. Multiple Linear Regression to Predict CO2 Emissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89a30eb-e72a-4078-9c8c-94a32357595f",
   "metadata": {},
   "source": [
    "Before beginning this section of the homework, please read [this section of the textbook](https://inferentialthinking.com/chapters/17/6/Multiple_Regression.html) on Multiple Linear Regression!\n",
    "\n",
    "What we've done so far in this class is called Simple Linear Regression (SLR), which involves one attribute to estimate a single numerical outcome. Precisely, the equation for the regression line has the following form: $$y = \\text{slope} \\cdot x+\\text{intercept}$$ Here, $x$ is the attribute, and we predict the value of $y$ by applying a slope and adding an intercept.\n",
    "\n",
    "Now, we will extend this idea to Multiple Linear Regression (MLR), which uses multiple attributes instead of just one. We make the prediction by multiplying each attribute value by its corresponding slope and summing them all together. The equation for the regression line has the following form: $$y = \\text{slope}_1 \\cdot x_1 + \\text{slope}_2 \\cdot x_2+ ... +\\text{slope}_k \\cdot x_k$$ for $k$ predictor variables. Here, $x_1$, $x_2$, $\\cdots$, $x_k$ represent different numerical predictor variables from the dataset, and we still predict a single numerical output $y$. Each predictor variable gets its own slope. Note that in this homework, our equation for the regression line will not have an intercept, but in general, the equation for the regression line can have an intercept!\n",
    "\n",
    "We use MLR when we believe more than one attribute influences the outcome we are trying to predict. To build the model, we split the dataset into a training set and a testing set. We use the training set to find the best slopes, and then evaluate its performance using Root Mean Squared Error (RMSE) on the testing set.\n",
    "\n",
    "In this part of the homework, we will use MLR to predict the CO2 emissions of a car using its engine size, cylinders, city fuel consumption, and highway fuel consumption."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3513ae80-5ff2-44e8-9c05-53913547bead",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "__Question 2.1__ In order to accurately assess how well a model can generalize and predict unseen data, it is important to first divide your dataset into a training set and a test set. Fill in the following code to first select the columns for engine size, cylinders, city fuel consumption, highway fuel consumption, and emissions. Then, to shuffle the data, reserve the first $1000$ data points for the test set, and assign the rest to the training set. __(6 Points)__\n",
    "\n",
    "Note: Do __not__ use `tbl.split` (you will not pass the autograder). Take a look at [Section 17.2.2](https://inferentialthinking.com/chapters/17/2/Training_and_Testing.html#generating-a-test-set) on how to get your training and test sets.\n",
    "\n",
    "Hint: `numerical_co2` should be a table of only the numerical columns from `co2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff60ff5-03f1-4796-8e9c-61d16f4f6b6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(8) #DO NOT CHANGE\n",
    "\n",
    "numerical_co2 = ...\n",
    "total_rows = ...\n",
    "shuffled_tbl = ...\n",
    "\n",
    "test_set = ...\n",
    "training_set = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7ce93a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdbc14d-2b03-41dd-82cb-f1f6cfff2814",
   "metadata": {},
   "source": [
    "Now the question is: How do we obtain the slopes ($\\text{slope}_1, \\text{slope}_2, ... \\text{slope}_k$) that minimizes the RMSE (reminder that the RMSE helps quantify the average size of the error our prediction model makes on any given testing observation). Well, our end result is going to look something like `minimize(fit)` where `fit` is a function that takes in an array of slopes and returns the RMSE of our predictions. However, there is a lot that goes into this calculation; let's take this one step at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402ec49c-0182-44d0-8e10-3d85738df8bf",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "__Question 2.2__ Define the function `predict` that takes in an array of slopes and a row object of attributes, and returns a number representing the corresponding prediction. You may assume that the array of slopes and the row object of attributes will be of the same length. __(3 Points)__\n",
    "\n",
    "Hint 1: Take a look at [Section 17.6.2](https://inferentialthinking.com/chapters/17/6/Multiple_Regression.html#multiple-linear-regression)\n",
    "\n",
    "Hint 2: You can perform array arithmetic on row objects as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2317a7a3-5c33-4d32-b938-8c27a2c06c68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(slopes, attributes):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f489560",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc350c7-f365-4482-9989-b04374be6327",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "__Question 2.3__ Now that we've defined a function that returns a prediction given an array of slopes and a row object of attributes, let's define `rmse` which takes in an array of slopes, a _table_ of attributes that we would like to use in our prediction, and an array of the _true_ values of y we want to predict. The function should return the RMSE of our predictions. __(10 Points)__\n",
    "\n",
    "Hint: Take a look at [Section 17.3](https://inferentialthinking.com/chapters/17/3/Rows_of_Tables.html) for a review on row objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ff194d-7cc9-4085-b574-f1ac44b02ae3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rmse(slopes, attributes, y):\n",
    "    ...\n",
    "    for ...:\n",
    "        ...\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2179f57c-8aad-44b5-8248-c9cb66b6ad7f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Let's test out the `rmse` function we just defined on our training set with some made up slope values that definitely are not optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbd4704-ed3b-4e33-835f-d70bcc0563a4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "train_attributes = training_set.drop(\"Emissions\")\n",
    "train_emissions = training_set.column(\"Emissions\")\n",
    "\n",
    "fake_slopes = make_array(1,1,1,1)\n",
    "rmse(fake_slopes, train_attributes, train_emissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de234306",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d1094d-93d9-4757-9614-4163b73d8dac",
   "metadata": {},
   "source": [
    "Those are some pretty big errors! It's quite clear that the optimal array of slopes is not just a bunch of 1's. However, now that we've defined `rmse`, we are finally ready to define `train_fit`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d93a138-08d7-4963-a39b-9d8e73ab4dad",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "__Question 2.4__ Define `train_fit`, which takes in an array of slopes and returns the RMSE on the <u>training set</u>. __(5 Points)__\n",
    "\n",
    "Hint: We're looking to predict emissions from our attributes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd8e9fe-69a7-49be-83ee-ee0eb48e4cbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fit(slopes_array):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6ef843",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea7206b-a2fe-40b6-a76a-29b0a53d20b3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "__Question 2.5__ Obtain the array of slopes that minimize the RMSE on the training set, and assign that to `best_slopes`. __(4 Points)__\n",
    "\n",
    "*Hint*: Make sure to use `fake_slopes` as one of your arguments. When the numerical optimization begins, the model might try out some inoptimal slopes first as it's searching for what will eventually be the right ones -- meaning, the ones that minimize RMSE!\n",
    "\n",
    "Note: Take a look at [Section 17.6.2](https://inferentialthinking.com/chapters/17/6/Multiple_Regression.html#multiple-linear-regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3475b1cd-4599-4476-9d51-a3dd5ce2e628",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This cell might take around one minute to run\n",
    "best_slopes = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b046474b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c7e69e-aeb7-4841-9297-5113fe4fc6dc",
   "metadata": {},
   "source": [
    "Let's see how well our optimal model performs on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6797f9-899b-473c-8b06-5f81e8be25f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fit(best_slopes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346780f9-b16b-4c74-a9ee-cf85cd0f1f0d",
   "metadata": {},
   "source": [
    "Not bad at all! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef95fc9-ea34-4fd9-b784-f014447bc763",
   "metadata": {},
   "source": [
    "Let's take a look at the values in `best_slopes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8409f7-f8a8-469a-aab4-1dbf00966508",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_slopes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd295239-6502-406e-bc02-0bfec36d2943",
   "metadata": {},
   "source": [
    "That seems a bit weird... doesn't it? Let's look at `train_attributes` again, the table of attributes we use to predict an emissions value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dacc396-63c9-44d7-9188-965477867729",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_attributes.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dead819-9c70-476f-899b-7f6ffc004f0f",
   "metadata": {},
   "source": [
    "You might have noticed something surprising: even though `Engine` and `Emissions` had a strong positive correlation (with an r value of around 0.85), the slope value for `Engine` obtained in MLR, which is denoted by the first element in the `best_slopes` array, is negative.\n",
    "\n",
    "This happens when the `Engine` attribute is correlated with other attributes in the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a593cd-f4e8-4344-8b4a-b89e5f4cdbab",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "__Question 2.6__ Now that we've obtained the array of slope values that minimize the RMSE, it's time to assess the performance of our model on the test set! Assign `test_rmse` to the RMSE obtained by using our regression line on the test set. __(3 Points)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b58591a-04cc-4b6b-b97f-a4ab2bf2d645",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_attributes = ...\n",
    "test_emissions = ...\n",
    "\n",
    "test_rmse = ...\n",
    "test_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec45c76",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ef4eda-544d-445b-ae61-f6827e6dc42e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "---\n",
    "\n",
    "__Question 2.7__ Compare the values of the training RMSE and testing RMSE. What do the values suggest about our model's ability to perform well on unseen data? __(5 Points)__ \n",
    "\n",
    "*Hint*: If the testing RMSE was much larger than the training RMSE, what would this say about our model's ability to perform well on unseen data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9ac7b5",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e919c9-1d5f-4279-8dc0-4f36e9ab0038",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "Including many attributes in your Multiple Linear Regression can increase your model's ability to capture complex patterns, but at the same time, including _too_ many features can make your model prone to overfitting. \n",
    "\n",
    "---\n",
    "\n",
    "Suppose that we're restricted to using _only three attributes_ for our predictions. Let's try _removing_ the `Fuel (City)` attribute, and only using `Engine`, `Cylinders`, and `Fuel (Hwy)` in our predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d54835-7688-474b-b08c-fbdb9cd001b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rmse_nocity(slopes):\n",
    "    return rmse(slopes, train_attributes.drop(\"Fuel (City)\"), train_emissions)\n",
    "\n",
    "best_slopes_nocity = minimize(train_rmse_nocity, start = make_array(1,1,1), smooth = True, array = True)\n",
    "best_slopes_nocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ec967e-a00c-4142-9c92-a338763b4273",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nocity_rmse = rmse(best_slopes_nocity, train_attributes.drop(\"Fuel (City)\"), train_emissions)\n",
    "test_nocity_rmse = rmse(best_slopes_nocity, test_attributes.drop(\"Fuel (City)\"), test_emissions)\n",
    "print(f\"Training RMSE excluding Fuel (City): {train_nocity_rmse}\")\n",
    "print(f\"Test RMSE excluding Fuel (City): {test_nocity_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8384267c-eb42-4be5-afe0-f763a41a3ee8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "---\n",
    "\n",
    "__Question 2.8__ Notice how both the Training RMSE and Test RMSE barely increased, even though we fully omitted one attribute from our predictions! Why could have removing `Fuel (City)` from our predictions led to a negligible decrease in the accuracy of our predictions? __(5 Points)__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a894e682",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5f64ae-4a5f-4a8e-9de5-94ee7f73f757",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## 3. Exploration of SwingVision Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b60503a-8768-40f0-be44-9845fa4d21f2",
   "metadata": {},
   "source": [
    "In this next exploration, we will be working with data from SwingVision that contains information about tennis shots hit by players. [SwingVision](https://swing.vision/) is a startup founded by previous Data 8 professor Swupnil Sahai that analyzes tennis and pickleball players' forms and playing statistics, providing feedback to improve their game!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20976a10",
   "metadata": {},
   "source": [
    "Run the following cell to load information about the dataset and preview the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f31d2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Table().read_table(\"shots_cleaned.csv\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed62aa7",
   "metadata": {},
   "source": [
    "For this exploration, we'll look at a cleaned version of this dataset and assign it to `shots`. Note that \"hit\" refers to when the ball is hit by the racket, and \"bounce\" refers to when the ball bounces on the court."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f540d1-95c1-4a8e-ae80-2d037580a8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "shots = Table().read_table(\"shots_cleaned.csv\").select(\"match_id\", \n",
    "                                                   \"set_id\", \n",
    "                                                   \"game_id\", \n",
    "                                                   \"hit_type\", \n",
    "                                                   \"hit_court_side\", \n",
    "                                                   \"hit_velocity\",\n",
    "                                                   \"bounce_court_side\", \n",
    "                                                   \"bounce_location_long\", \n",
    "                                                   \"bounce_location\")\n",
    "shots.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a684d3-2c28-4374-abfb-14b113a08f91",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "__Question 3.1__ In a game of tennis, keeping constant pressure on the opponent is very important. There's a lot of data in the table, let's limit our analysis to the following shots:\n",
    "\n",
    "* Shots that were considered as \"ground_stroke\"\n",
    "* Shots that were hit by the player closer to the camera (i.e., \"near\")\n",
    "* Shots that bounced on the other side of the court (i.e., \"far\")\n",
    "* Shots that were _not_ out.\n",
    "\n",
    "Name this new table `ground_strokes`, and only keep the columns `hit_velocity`, `bounce_location_long`, `bounce_location`. __(5 Points)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ef99b0-934c-4236-90fc-4ca84391a99f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(8) #DO NOT CHANGE\n",
    "\n",
    "ground_strokes = ...\n",
    "\n",
    "ground_strokes = ground_strokes.sample(with_replacement = False).take(np.arange(1000))\n",
    "ground_strokes.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1247bbd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bf4e1f-c219-4e13-a3dc-b7944dbd4f05",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "__Question 3.2__ Assign `unique_bounce_locations` to a two-column table: the first column should contain each unique value in `bounce_location_long`; the second column should contain the number of times that each of these unique values appear in the `ground_strokes` table. __(3 Points)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae21658b-64f8-4196-82b4-b31143f38de9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unqiue_bounce_locations = ...\n",
    "unqiue_bounce_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebb44dd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4edcc04-815a-4aeb-b50d-b0dc90c0ec4e",
   "metadata": {},
   "source": [
    "Notice that the _hit_velocity_ and _bounce_location_ columns don't contain ordinary integers or strings like we're used to seeing. In fact, each value in _hit_velocity_ and _bounce_location_ is a _list_ of coordinates (x, y, z)! If you don't know what a list is, you can think of it as something similar to an array. Let's add columns to the `ground_strokes` table that contains the _individual coordinates_ as floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c951e0-41d6-423c-8cf2-7412cbcb68c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell\n",
    "import ast\n",
    "def extract_x(lst):\n",
    "    return ast.literal_eval(lst)[0]\n",
    "\n",
    "def extract_y(lst):\n",
    "    return ast.literal_eval(lst)[1]\n",
    "\n",
    "def extract_z(lst):\n",
    "    return ast.literal_eval(lst)[2]\n",
    "\n",
    "hit_velocity_x = make_array()\n",
    "hit_velocity_y = make_array()\n",
    "hit_velocity_z = make_array()\n",
    "\n",
    "for coordinates in ground_strokes.column(\"hit_velocity\"):\n",
    "    hit_velocity_x = np.append(hit_velocity_x, extract_x(coordinates))\n",
    "    hit_velocity_y = np.append(hit_velocity_y, extract_y(coordinates))\n",
    "    hit_velocity_z = np.append(hit_velocity_z, extract_z(coordinates))\n",
    "\n",
    "bounce_x = make_array()\n",
    "bounce_y = make_array()\n",
    "bounce_z = make_array()\n",
    "\n",
    "for coordinates in ground_strokes.column(\"bounce_location\"):\n",
    "    bounce_x = np.append(bounce_x, extract_x(coordinates))\n",
    "    bounce_y = np.append(bounce_y, extract_y(coordinates))\n",
    "    bounce_z = np.append(bounce_z, extract_z(coordinates))\n",
    "\n",
    "coords = ground_strokes.with_columns(\n",
    "    \"hit_velocity_x\", hit_velocity_x, \"hit_velocity_y\", hit_velocity_y, \"hit_velocity_z\", hit_velocity_z).with_columns(\n",
    "    \"bounce_x\", bounce_x, \"bounce_y\", bounce_y, \"bounce_z\", bounce_z).drop(\"hit_velocity\", \"bounce_location\").where(\n",
    "    \"hit_velocity_z\", are.below(15))\n",
    "\n",
    "coords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f07443-ef8c-4b9e-8927-0623a4cb4168",
   "metadata": {},
   "source": [
    "In this exploration, we want to predict or classify how _deep_ a shot lands, based on the initial velocity of the ball when it is hit by a player. To describe the coordinates (x,y,z):\n",
    "\n",
    "* _x_ describes left/right (right being positive)\n",
    "* _y_ describes forward/backward (forward being positive)\n",
    "* _z_ describes up/down (up being positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c79f582-d24a-4fa9-bfcd-0ed7e27380c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell\n",
    "colors = {'service_box': 'orange', 'no_mans_land': 'blue'}\n",
    "color_list = [colors[group] for group in coords['bounce_location_long']]\n",
    "plt.scatter(data = coords.where('bounce_location_long', 'service_box'), x = \"hit_velocity_y\", y = \"hit_velocity_z\", s = 2, color = 'orange', label='service_box')\n",
    "plt.scatter(data = coords.where('bounce_location_long', 'no_mans_land'), x = \"hit_velocity_y\", y = \"hit_velocity_z\", s = 2, color = 'blue', label='no_mans_land')\n",
    "plt.xlabel(\"Hit Velocity (y coordinate)\")\n",
    "plt.ylabel(\"Hit Velocity (z coordinate)\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69dbda8-8ce5-4293-be0b-54c79532475b",
   "metadata": {},
   "source": [
    "We can see a fairly clear decision boundary between shots that land in \"no_mans_land\", colored in blue, and shots that land in the \"service_box\", colored in orange."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccb24a6-adb7-46b3-b628-a218b4f3d61f",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## 4. k-Nearest Regression with SwingVision Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cf00e7-53d0-4281-af83-2aeae3eacea8",
   "metadata": {},
   "source": [
    "For a refresher on kNN, review [Chapter 17](https://inferentialthinking.com/chapters/17/Classification.html) from the textbook!\n",
    "\n",
    "kNN regression is a method used to predict a numerical value based on nearby data points. To make a prediction, we first calculate the Euclidean distance between the point we are trying to predict and each point in the data set. We then find the k closest points, known as the nearest neighbors. Instead of taking a majority vote like we did in kNN classificaiton, we take the average of the values we are trying to predict from the nearest neighbors. This average value becomes our prediction.\n",
    "\n",
    "Sure, we can classify (with some degree of accuracy) whether a shot we hit will land in the _service_box_ or _no_mans_land_ based on it's initial velocity, but maybe we would want to be more specific about how _deep_ our shot will land on the opponent's side. After all, the deeper the shot lands, the more pressure you put on the opponent! This is where kNN regression is useful \u2014 rather than labeling the bounce location, we can use it to predict the depth (numerical position) where the ball is likely to bounce."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b570678f-fc4f-4d76-95a6-9654afeba597",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "__Question 4.1__ Again, let's split our `coords` dataset into a training set and a test set, reserving the first $200$ shots for the test set and putting the rest into the training set. __(6 Points)__\n",
    "\n",
    "Note: Do __not__ use `tbl.split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0177803-8763-4ccc-a5ca-59dd66aca547",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(8) #DO NOT CHANGE\n",
    "\n",
    "num_shots = ...\n",
    "shuffled_coords = ...\n",
    "\n",
    "test_coords = ...\n",
    "training_coords = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88b92e9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6eb585-9b4f-4eeb-b8b4-aeedafe35d99",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "__Question 4.2__ As always, let's define a function that calculates the distance between two points according to the relevant attributes. Complete the `distance` function that takes in two rows, and calculates the Euclidean distance using `hit_velocity_y` and `hit_velocity_z`. __(3 Points)__\n",
    "\n",
    "Note: The formula for Euclidean distance is $\\sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6632077e-22d8-46fe-90d3-1e5cab5cb921",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def distance(row1, row2):\n",
    "    y_diff = ...\n",
    "    z_diff = ...\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3545f3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a177fb1a-85c0-419f-b5a0-27625ee81977",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "__Question 4.3__ Define a function `predict_nn` that takes in a row, and returns the predicted _y_ coordinate of where the ball landed based on the k nearest neighbors. __(10 Points)__\n",
    "\n",
    "*Hint*: Make sure to read the introduction of Question 4 carefully before approaching this problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd03644c-0ef9-423c-a90c-1e3b7d5c1847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_nn(point, k):\n",
    "    num_training = ...\n",
    "    dists = ...\n",
    "    for ...:\n",
    "        ...\n",
    "    train_dists = ...\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9598ab8e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f46e1aa-5540-49c0-bd78-26f27e51865d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "__Question 4.4__ Now, perform kNN regression with $k = 7$ on the test set defined earlier. Calculate the RMSE of our predictions. __(8 Points)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5f88f8-df32-4299-a038-a30b1a0835c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nn_predictions = ...\n",
    "num_test = ...\n",
    "...\n",
    "\n",
    "knn_regression_rmse = ...\n",
    "knn_regression_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b195cfb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113316b1-8530-4e99-b369-ba217bf4be36",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## 5. **(OPTIONAL)** kNN Classification with SwingVision Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff454b2",
   "metadata": {},
   "source": [
    "Now, we will develop a k-Nearest Neighbors (kNN) classifier to classify how deep a shot lands by predicting whether it bounces in the \"service_box\" or in \"no_mans_land\", using the ball's inital velocity in the forward/backward (`hit_velocity_y`) and up/down directions (`hit_velocity_z`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a367df3-b371-4237-99f6-b5d080bf19b2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "__Question 5.1__ Define the function `classify` that takes in a point (a row object) and `k`, and classifies that point using the data in the training set.\n",
    "\n",
    "*Hint*: Take a look at [Section 17.4.5](https://inferentialthinking.com/chapters/17/4/Implementing_the_Classifier.html#implementation-step-1) on how to implement this function.\n",
    "\n",
    "Note: You don't need to follow the skeleton code to answer this question!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502d36f9-a609-4295-8b44-29907d34685c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def classify(point, k):\n",
    "    num_training = ...\n",
    "    dists = ...\n",
    "    for ...:\n",
    "        ...\n",
    "    train_dists = ...\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99a80d9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48909686",
   "metadata": {},
   "source": [
    "Let's test our classifier on the first data point in our test set with $k = 7$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e050599a-e073-4e15-a2b7-b41c30e6cec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(test_coords.row(0), 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9862bec-950b-4d15-87ed-45a5cbbeeb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_coords.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d269348-5cc9-4d37-9c2c-03fa5aea078c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "__Question 5.2__ Define a function `accuracy` which takes in an array of predictions (an array of actual values) and returns the proportion of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1c3ed4-9be3-4bff-bf0b-6a0da3a491e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracy(preds, y):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ad48fa",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88972746-eb2f-4681-a197-b3de08715ee3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "__Question 5.3__ Now, determine the accuracy of the kNN classifier we developed on the test set we defined earlier, using $k = 7$.\n",
    "\n",
    "**Hint**: Consider using a for loop to store the prediction of each shot from `test_coords` in the array `predictions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa7a2a3-648d-4576-bb02-0d2c845c9e0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_test = ...\n",
    "predictions = ...\n",
    "...\n",
    "\n",
    "accuracy(predictions, test_coords.column(\"bounce_location_long\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a2bf58",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180198fc",
   "metadata": {},
   "source": [
    "You're done with Homework 12!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e1c67e",
   "metadata": {},
   "source": [
    "## Pets of Data 8\n",
    "\n",
    "Vava hopes you enjoyed Homework 11 as much as she enjoys her new hairdo!\n",
    "\n",
    "<img src=\"vava.jpeg\" width=\"40%\" alt=\"White bichon fris\u00e9 with a new makeover\"/>\n",
    "\n",
    "Congrats on finishing Homework 11!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5170ee",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Written Work Submission\n",
    "\n",
    "Below, you will see two cells. Running the first cell will automatically generate a PDF of all questions that need to be manually graded, and running the second cell will automatically generate a zip with your autograded answers. You are responsible for submitting both the coding portion (the zip) and the written portion (the PDF) to their respective Gradescope portals. **Please save before exporting!**\n",
    "\n",
    "> **Important: You must correctly assign the pages of your PDF after you submit to the correct gradescope assignment. If your pages are not correctly assigned and/or not in the correct PDF format by the deadline, we reserve the right to award no points for your written work.**\n",
    "\n",
    "If there are issues with automatically generating the PDF in the first cell, you can try downloading the notebook as a PDF by clicking on `File -> Save and Export Notebook As... -> Webpdf`. If that doesn't work either, you can manually take screenshots of your answers to the manually graded questions and submit one single PDF of your screenshots. Either way, **you are responsible for ensuring your submission follows our requirements, we will NOT be granting regrade requests for submissions that don't follow instructions.**\n",
    "\n",
    "**You must submit the PDF generated via one of these methods, we will not accept screenshots or Word documents.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50f9482",
   "metadata": {},
   "outputs": [],
   "source": [
    "from otter.export import export_notebook\n",
    "from os import path\n",
    "from IPython.display import display, HTML\n",
    "name = 'hw12'\n",
    "export_notebook(f\"{name}.ipynb\", filtering=True, pagebreaks=True)\n",
    "if(path.exists(f'{name}.pdf')):\n",
    "    display(HTML(f\"Download your PDF <a href='{name}.pdf' download>here</a>.\"))\n",
    "else:\n",
    "    print(\"\\n Pdf generation failed, please try the other methods described above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462c01a6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b80b34",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6af2e5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29c5595",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2543f1e",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1_1": {
     "name": "q1_1",
     "points": [
      0,
      0,
      3
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(standardize(co2, 'Engine'), np.ndarray)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> type(standardize(co2, 'Engine').item(0)) in set([float, np.float64])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> def get_hash(num):\n...     \"\"\"Helper function for assessing correctness.\"\"\"\n...     return hashlib.md5(str(num).encode()).hexdigest()\n>>> get_hash(np.round(standardize(co2, 'Engine').item(0), 4)) == '6eb876585034f98e94657ca747d7d1cc'\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1_2": {
     "name": "q1_2",
     "points": [
      0,
      3
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> -1 <= correlation(co2, 'Engine', 'Emissions') <= 1\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> def get_hash(num):\n...     \"\"\"Helper function for assessing correctness.\"\"\"\n...     return hashlib.md5(str(num).encode()).hexdigest()\n>>> get_hash(np.round(correlation(co2, 'Engine', 'Emissions'), 4)) == '3a02549881dc0cb05bc1d7baf1685fff'\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1_3": {
     "name": "q1_3",
     "points": [
      0,
      0,
      3
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> -1 <= correlation(co2, 'Engine', 'Emissions') <= 1\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.all(numerical_column_names == make_array('Engine', 'Cylinders', 'Fuel (City)', 'Fuel (Hwy)'))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> def get_hash(num):\n...     \"\"\"Helper function for assessing correctness.\"\"\"\n...     return hashlib.md5(str(num).encode()).hexdigest()\n>>> get_hash(np.round(current_r, 4)) == '99156cd6931a2455506ab6d5c31b62a9'\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1_4": {
     "name": "q1_4",
     "points": [
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(highest_correlation) == int and 1 <= highest_correlation <= 4\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1_6": {
     "name": "q1_6",
     "points": [
      0,
      0,
      0,
      3
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> unique_cylinders_values.num_rows == 8\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> unique_cylinders_values.column(1).item(3)\n2446",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> unique_cylinders_values.column(0).item(0)\n3",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> def get_hash(num):\n...     \"\"\"Helper function for assessing correctness.\"\"\"\n...     return hashlib.md5(str(num).encode()).hexdigest()\n>>> get_hash(unique_cylinders_values.column(1).item(4)) == '28fc2782ea7ef51c1104ccf7b9bea13d'\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1_7": {
     "name": "q1_7",
     "points": [
      0,
      1.5,
      1.5
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 'Cylinders_and_City' in co2_new.labels\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> co2_new.column('Cylinders_and_City').item(4)\n18.1",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> def get_hash(num):\n...     \"\"\"Helper function for assessing correctness.\"\"\"\n...     return hashlib.md5(str(num).encode()).hexdigest()\n>>> get_hash(np.round(strong_correlation, 4)) == '79591d2930dca681c78d688dfc32af32'\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1_8": {
     "name": "q1_8",
     "points": [
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(answer) == bool\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_1": {
     "name": "q2_1",
     "points": [
      0,
      0,
      0,
      0,
      6
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.all(numerical_co2.labels == make_array('Engine', 'Cylinders', 'Fuel (City)', 'Fuel (Hwy)', 'Emissions'))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.all(test_set.labels == make_array('Engine', 'Cylinders', 'Fuel (City)', 'Fuel (Hwy)', 'Emissions'))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.all(test_set.labels == make_array('Engine', 'Cylinders', 'Fuel (City)', 'Fuel (Hwy)', 'Emissions'))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> shuffled_tbl.num_rows == 7385\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> test_set.column('Fuel (Hwy)').item(0) == 10.1\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_2": {
     "name": "q2_2",
     "points": [
      0,
      3
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> slopes = make_array(1, 2, 3)\n>>> attributes = make_array(4, 5, 6)\n>>> predict(slopes, attributes) == 32\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> slopes = make_array(0, 1, 2)\n>>> attributes = make_array(7, 8, 9)\n>>> predict(slopes, attributes) == 26\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_3": {
     "name": "q2_3",
     "points": [
      0,
      10
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(rmse(fake_slopes, train_attributes, train_emissions)) in set([float, np.float64])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> def get_hash(num):\n...     \"\"\"Helper function for assessing correctness.\"\"\"\n...     return hashlib.md5(str(num).encode()).hexdigest()\n>>> get_hash(np.round(rmse(fake_slopes, train_attributes, train_emissions), 4)) == '476915be7ef34cd4334ccaed88c212b2'\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_4": {
     "name": "q2_4",
     "points": [
      0,
      5
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(train_fit(make_array(8, 8, 8, 8))) in set([float, np.float64])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> def get_hash(num):\n...     \"\"\"Helper function for assessing correctness.\"\"\"\n...     return hashlib.md5(str(num).encode()).hexdigest()\n>>> get_hash(np.round(train_fit(make_array(8, 8, 8, 8)), 4)) == '2084462bf54dcd204bf26206428c01c4'\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_5": {
     "name": "q2_5",
     "points": [
      1,
      1,
      2
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(train_fit(best_slopes), 22.753604146634835)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> def get_hash(num):\n...     \"\"\"Helper function for assessing correctness.\"\"\"\n...     return hashlib.md5(str(num).encode()).hexdigest()\n>>> get_hash(np.round(best_slopes.item(0), 4)) == 'fcf6a9732c9e8eabb3f99b5d2de6c92e'\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> def get_hash(num):\n...     \"\"\"Helper function for assessing correctness.\"\"\"\n...     return hashlib.md5(str(num).encode()).hexdigest()\n>>> get_hash(np.round(best_slopes.item(1), 4)) == '69fca06fd6ab7330b32d310716051dba'\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_6": {
     "name": "q2_6",
     "points": [
      0,
      3
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(test_rmse) in set([float, np.float64])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> def get_hash(num):\n...     \"\"\"Helper function for assessing correctness.\"\"\"\n...     return hashlib.md5(str(num).encode()).hexdigest()\n>>> get_hash(np.round(test_rmse, 4)) == 'd45b282417ae86b295a7bfa3edaad8b1'\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3_1": {
     "name": "q3_1",
     "points": [
      0,
      2,
      3
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> ground_strokes.num_rows == 1000\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.all(ground_strokes.labels == make_array('hit_velocity', 'bounce_location_long', 'bounce_location'))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> ground_strokes.column(1).item(4)\n'no_mans_land'",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3_2": {
     "name": "q3_2",
     "points": [
      0,
      3
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> unqiue_bounce_locations.num_rows == 2\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> unqiue_bounce_locations.column('count').item(0) + unqiue_bounce_locations.column('count').item(1) == 1000\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4_1": {
     "name": "q4_1",
     "points": [
      0,
      6
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> shuffled_coords.num_rows == 996\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> def get_hash(num):\n...     \"\"\"Helper function for assessing correctness.\"\"\"\n...     return hashlib.md5(str(num).encode()).hexdigest()\n>>> get_hash(np.round(test_coords.column('hit_velocity_x').item(0), 4)) == '3ba81a508ad7c81fbe46780facf9d3a5'\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4_2": {
     "name": "q4_2",
     "points": [
      3
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def get_hash(num):\n...     \"\"\"Helper function for assessing correctness.\"\"\"\n...     return hashlib.md5(str(num).encode()).hexdigest()\n>>> get_hash(np.round(distance(training_coords.row(0), training_coords.row(1)), 4)) == '9728b30cb5dca6c44fd8293f804a5fbe'\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4_3": {
     "name": "q4_3",
     "points": [
      0,
      10
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(predict_nn(test_coords.row(0), 3)) in set([float, np.float64])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> def get_hash(num):\n...     \"\"\"Helper function for assessing correctness.\"\"\"\n...     return hashlib.md5(str(num).encode()).hexdigest()\n>>> get_hash(np.round(predict_nn(test_coords.row(0), 3), 4)) == 'cdcada915d0258f9b9e7b37252418a00'\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4_4": {
     "name": "q4_4",
     "points": [
      0,
      8
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(nn_predictions) == 200\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> def get_hash(num):\n...     \"\"\"Helper function for assessing correctness.\"\"\"\n...     return hashlib.md5(str(num).encode()).hexdigest()\n>>> get_hash(np.round(knn_regression_rmse, 4)) == '26e36142112bb6ff28252841573b1c0f'\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5_1": {
     "name": "q5_1",
     "points": [
      0,
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(classify(test_coords.row(0), 7)) == str\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> classify(test_coords.row(0), 7)\n'no_mans_land'",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5_2": {
     "name": "q5_2",
     "points": [
      0,
      0,
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(accuracy(make_array(4, 3, 2), make_array(1, 2, 4))) in set([float, np.float64])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> 0 <= accuracy(make_array(4, 3, 2), make_array(1, 3, 4)) <= 1\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> def get_hash(num):\n...     \"\"\"Helper function for assessing correctness.\"\"\"\n...     return hashlib.md5(str(num).encode()).hexdigest()\n>>> get_hash(np.round(accuracy(make_array(4, 3, 2), make_array(1, 3, 4)), 4)) == 'd80cd8a9bc59ca0c1f479e4eca3c64be'\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5_3": {
     "name": "q5_3",
     "points": [
      0,
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 0 <= accuracy(predictions, test_coords.column('bounce_location_long')) <= 1\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> def get_hash(num):\n...     \"\"\"Helper function for assessing correctness.\"\"\"\n...     return hashlib.md5(str(num).encode()).hexdigest()\n>>> get_hash(np.round(accuracy(predictions, test_coords.column('bounce_location_long')), 4)) == '57eeec0a6974ecb4e9fcf68fab052f7b'\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}